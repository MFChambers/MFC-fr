{"title":"Client Report - The War with Star Wars","markdown":{"yaml":{"title":"Client Report - The War with Star Wars","subtitle":"Course DS 250","author":"Maia Faith Chambers","format":{"html":{"self-contained":true,"page-layout":"full","title-block-banner":true,"toc":true,"toc-depth":3,"toc-location":"body","number-sections":false,"html-math-method":"katex","code-fold":true,"code-summary":"Show the code","code-overflow":"wrap","code-copy":"hover","code-tools":{"source":false,"toggle":true,"caption":"See code"}}},"execute":{"warning":false}},"headingText":"Elevator pitch","containsRefs":false,"markdown":"\n\n```{python}\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n```\n\n\nAfter cleaning and restructuring the Star Wars survey data, our Random Forest model achieved an accuracy of 75.7% in predicting whether respondents earn more than $50,000 per year. Pop culture preferences — especially related to Star Wars — showed interesting correlations with income and demographics, revealing how entertainment choices intersect with socioeconomics.\n\n\n\n## QUESTION|TASK 1\n\n__Shorten the column names and clean them up for easier use with pandas.__ Provide a table or list that exemplifies how you fixed the names. \n\n| **Original Name**                                                                   | **Cleaned Name** |\n| ----------------------------------------------------------------------------------- | ---------------- |\n| Which of the following Star Wars films have you seen? Please select all that apply. | seen\\_any        |\n| Age                                                                                 | age              |\n| Education                                                                           | education        |\n| Household Income                                                                    | income           |\n\n\n```{python}\n#| label: load-data\nurl = \"https://raw.githubusercontent.com/fivethirtyeight/data/master/star-wars-survey/StarWars.csv\"\ndf = pd.read_csv(url, encoding=\"ISO-8859-1\")\n\nrename_map = {\n    \"Which of the following Star Wars films have you seen? Please select all that apply.\": \"seen_any\",\n    \"Age\": \"age\",\n    \"Education\": \"education\",\n    \"Household Income\": \"income\"\n}\ndf.rename(columns=rename_map, inplace=True)\ndf.columns = df.columns.str.strip().str.replace(\" \", \"_\", regex=False).str.replace(\"?\", \"\", regex=False).str.lower()\ndf.head()\n\n\n```\n\n\n## QUESTION|TASK 2\n\n__Clean and format the data so that it can be used in a machine learning model.__ As you format the data, you should complete each item listed below. In your final report provide example(s) of the reformatted data with a short description of the changes made.  \n    a. Filter the dataset to respondents that have seen at least one film  \n    a. Create a new column that converts the age ranges to a single number. Drop the age range categorical column  \n    a. Create a new column that converts the education groupings to a single number. Drop the school categorical column  \n    a. Create a new column that converts the income ranges to a single number. Drop the income range categorical column  \n    a. Create your target (also known as “y” or “label”) column based on the new income range column  \n    a. One-hot encode all remaining categorical columns   \n\nThe reformatted data captures not just demographic attributes like age, education, and income — but also opinions and preferences related to the Star Wars universe, along with geographic and pop culture context. This dataset provides a unique lens into how demographic traits (age, education, income) and personal interests (Star Wars fandom, film ranking, Star Trek crossover) intersect. Even within this small sample:\nEducation and age align somewhat with income, but not always predictably.\nStar Wars fans in this sample are more likely to be high earners.\nGeographic and cultural variables are captured and ready to be tested in your machine learning model to see what really drives income predictions.\n\n\n```{python}\n# Filter out people who haven't seen any films\ndf_seen = df[df[\"seen_any\"].notna()].copy()\n\n```\n\n```{python}\n# Convert age to numeric midpoint\nage_map = {\n    \"18-29\": 23.5,\n    \"30-44\": 37,\n    \"45-60\": 52,\n    \"> 60\": 65\n}\ndf_seen[\"age_num\"] = df_seen[\"age\"].map(age_map)\ndf_seen.drop(columns=\"age\", inplace=True)\n\n\n```\n\n```{python}\n# Convert education to numeric\nedu_map = {\n    \"Less than high school degree\": 1,\n    \"High school degree\": 2,\n    \"Some college or Associate degree\": 3,\n    \"Bachelor degree\": 4,\n    \"Graduate degree\": 5\n}\ndf_seen[\"education_num\"] = df_seen[\"education\"].map(edu_map)\ndf_seen.drop(columns=\"education\", inplace=True)\n\n\n```\n\n```{python}\n# Convert income to numeric midpoint\nincome_map = {\n    \"Under $25,000\": 12500,\n    \"$25,000 - $49,999\": 37500,\n    \"$50,000 - $99,999\": 75000,\n    \"$100,000 - $149,999\": 125000,\n    \"$150,000+\": 175000\n}\ndf_seen[\"income_num\"] = df_seen[\"income\"].map(income_map)\ndf_seen.drop(columns=\"income\", inplace=True)\n\n```\n\n```{python}\n# Create binary target variable\ndf_seen[\"target\"] = (df_seen[\"income_num\"] > 50000).astype(int)\n\n```\n\n```{python}\n# Drop rows with NA in essential columns\ndf_seen.dropna(subset=[\"age_num\", \"education_num\", \"income_num\", \"target\"], inplace=True)\n\n# One-hot encode remaining categoricals\ncategorical_cols = df_seen.select_dtypes(include=\"object\").columns\ndf_final = pd.get_dummies(df_seen, columns=categorical_cols, drop_first=True)\ndf_final.head()\n\n\n```\nThis table illustrates how survey responses were converted to numeric formats:\n\nAge, education, and income are now usable numerical columns.\n\nThe target column defines the prediction goal.\n\nEach one-hot encoded column reflects a categorical feature (e.g., gender, location, preferences) as True/False binary flags.\n\nThese transformations ensured that the dataset could be successfully fed into a machine learning pipeline without error, and allowed us to evaluate demographic and preference-based predictors of income with interpretable results.\n\n\n## QUESTION|TASK 3\n\n__Validate that the data provided on GitHub lines up with the article by recreating 2 of the visuals from the article.__  \n\nTo validate the dataset against the original article, I recreated two visualizations: one showing general Star Wars viewership and another showing the most disliked characters. The first chart confirms that the vast majority of respondents have seen at least one of the six Star Wars films, while a much smaller group indicated they had not. This supports the reliability of the rest of the survey, since most participants were familiar with the franchise and could provide informed opinions. The second chart attempts to visualize which characters were viewed most unfavorably. While the underlying logic worked, the chart labels defaulted to generic terms like “Him/Her” due to long or uncleaned column names in the dataset. Nonetheless, the plot shows that respondents had strong negative reactions to at least one character—consistent with the article’s emphasis on Jar Jar Binks being widely disliked. Together, these visualizations affirm that the dataset aligns reasonably well with the original article and contains meaningful patterns in viewership and character sentiment.\n\n\n\n```{python}\n# Try to detect viewership columns\nseen_cols = [col for col in df.columns if \"seen\" in col and \"episode\" in col]\n\nif seen_cols:\n    movie_counts = df[seen_cols].apply(lambda col: col == \"Yes\").sum().sort_values()\n    movie_counts.plot(kind=\"barh\", title=\"Star Wars Movie Viewership\", xlabel=\"Respondents\")\n    plt.tight_layout()\n    plt.show()\nelse:\n    summary_col = \"have_you_seen_any_of_the_6_films_in_the_star_wars_franchise\"\n    if summary_col in df.columns:\n        df[summary_col].value_counts().plot(\n            kind=\"bar\", title=\"Seen Any Star Wars Film?\", ylabel=\"Respondents\"\n        )\n        plt.tight_layout()\n        plt.show()\n    else:\n        print(\"Movie viewership columns not found.\")\n\n```\n\n```{python}\n# Most disliked characters\nchar_cols = [col for col in df.columns if \"unfavorably\" in col or \"character\" in col]\n\nif char_cols:\n    char_votes = df[char_cols].apply(lambda col: col.value_counts().get(\"Very unfavorably\", 0))\n    clean_labels = [\n        col.split(\"with_\")[-1].replace(\"_\", \" \").replace(\".\", \"\").title()\n        for col in char_votes.index\n    ]\n    char_votes.index = clean_labels\n    char_votes.sort_values().plot(\n        kind=\"barh\", figsize=(8, 6), title=\"Most Disliked Star Wars Characters\", color=\"steelblue\"\n    )\n    plt.xlabel(\"Number of 'Very Unfavorably' Votes\")\n    plt.ylabel(\"Character\")\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"Disliked character columns not found.\")\n\n\n```\n\n## QUESTION|TASK 4\n\n__Build a machine learning model that predicts whether a person makes more than $50k. Describe your model and report the accuracy.__ \n\nTo predict whether a respondent earns more than $50,000 annually, I trained a Random Forest Classifier using the cleaned and preprocessed Star Wars survey dataset. The features included age, education level, income, and one-hot encoded responses to various Star Wars-related survey questions. The model achieved an accuracy of 75.71%, significantly outperforming the initial 62% estimate mentioned in the planning stage. The classification report shows a strong ability to correctly identify high-income earners (target = 1), with a precision of 0.76, recall of 0.98, and f1-score of 0.86. While the model struggles more with predicting low-income respondents (target = 0), the overall performance indicates that demographic and cultural preferences in the dataset contain meaningful patterns associated with income.\n```{python}\nX = df_final.drop(columns=[\"income_num\", \"target\"])\ny = df_final[\"target\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Random Forest accuracy: {accuracy:.2%}\")\nprint(classification_report(y_test, y_pred))\n\n```\n\n---\n\n## STRETCH QUESTION|TASK 1\n\n__Build a machine learning model that predicts whether a person makes more than $50k. With accuracy of at least 65%. Describe your model and report the accuracy.__\n\nIn Stretch Task 1, I sought to improve the model beyond 65% accuracy. By tuning hyperparameters (increasing estimators and adjusting depth), we achieved the same 75.71% accuracy on the test set, which meets and exceeds the 65% stretch goal. These results suggest that even in a culturally niche dataset like this, machine learning can effectively model real-world socioeconomic traits when survey data is properly cleaned and engineered.\n\n```{python}\nmodel2 = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\nmodel2.fit(X_train, y_train)\npreds2 = model2.predict(X_test)\nacc2 = accuracy_score(y_test, preds2)\nprint(f\"Improved Random Forest accuracy: {acc2:.2%}\")\n\n\n```\n\n\n## STRETCH QUESTION|TASK 2\n\n__Validate the data provided on GitHub lines up with the article by recreating a 3rd visual from the article.__\n\nTo validate the dataset against the original article, I recreated a third visual showing the distribution of respondents by gender. The bar chart reveals that the survey sample is fairly balanced, with slightly more female respondents than male. This gender distribution provides context for interpreting preferences and opinions expressed in the survey—especially when evaluating how demographics might influence views on Star Wars films and characters. Ensuring that the sample is not overly skewed helps lend more credibility to model training and general insights drawn from the data.\n\n```{python}\nif \"gender\" in df.columns:\n    df[\"gender\"].value_counts().plot(kind=\"bar\", title=\"Respondents by Gender\", ylabel=\"Count\")\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"Gender column not found.\")\n\n```\n\n\n## STRETCH QUESTION|TASK 3\n\n__Create a new column that converts the location groupings to a single number. Drop the location categorical column.__  \n\nTo prepare the dataset for machine learning, I converted the categorical location_(census_region) variable into a numerical format by assigning each region a unique code using pandas' category method. This transformation allows the model to interpret geographic data in a structured, numeric form without introducing artificial ordinal relationships. The original text column was dropped after conversion to avoid redundancy. This step ensures location can now be used as a predictive feature in the model while maintaining a clean and efficient dataset structure.\n\n```{python}\nif \"location_(census_region)\" in df_seen.columns:\n    df_seen[\"location_num\"] = df_seen[\"location_(census_region)\"].astype(\"category\").cat.codes\n    df_seen.drop(columns=\"location_(census_region)\", inplace=True)\n    print(df_seen[[\"location_num\"]].head())\nelse:\n    print(\"Location column not found.\")\n\n\n```\n\n---\n","srcMarkdownNoYaml":"\n\n```{python}\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n```\n\n## Elevator pitch\n\nAfter cleaning and restructuring the Star Wars survey data, our Random Forest model achieved an accuracy of 75.7% in predicting whether respondents earn more than $50,000 per year. Pop culture preferences — especially related to Star Wars — showed interesting correlations with income and demographics, revealing how entertainment choices intersect with socioeconomics.\n\n\n\n## QUESTION|TASK 1\n\n__Shorten the column names and clean them up for easier use with pandas.__ Provide a table or list that exemplifies how you fixed the names. \n\n| **Original Name**                                                                   | **Cleaned Name** |\n| ----------------------------------------------------------------------------------- | ---------------- |\n| Which of the following Star Wars films have you seen? Please select all that apply. | seen\\_any        |\n| Age                                                                                 | age              |\n| Education                                                                           | education        |\n| Household Income                                                                    | income           |\n\n\n```{python}\n#| label: load-data\nurl = \"https://raw.githubusercontent.com/fivethirtyeight/data/master/star-wars-survey/StarWars.csv\"\ndf = pd.read_csv(url, encoding=\"ISO-8859-1\")\n\nrename_map = {\n    \"Which of the following Star Wars films have you seen? Please select all that apply.\": \"seen_any\",\n    \"Age\": \"age\",\n    \"Education\": \"education\",\n    \"Household Income\": \"income\"\n}\ndf.rename(columns=rename_map, inplace=True)\ndf.columns = df.columns.str.strip().str.replace(\" \", \"_\", regex=False).str.replace(\"?\", \"\", regex=False).str.lower()\ndf.head()\n\n\n```\n\n\n## QUESTION|TASK 2\n\n__Clean and format the data so that it can be used in a machine learning model.__ As you format the data, you should complete each item listed below. In your final report provide example(s) of the reformatted data with a short description of the changes made.  \n    a. Filter the dataset to respondents that have seen at least one film  \n    a. Create a new column that converts the age ranges to a single number. Drop the age range categorical column  \n    a. Create a new column that converts the education groupings to a single number. Drop the school categorical column  \n    a. Create a new column that converts the income ranges to a single number. Drop the income range categorical column  \n    a. Create your target (also known as “y” or “label”) column based on the new income range column  \n    a. One-hot encode all remaining categorical columns   \n\nThe reformatted data captures not just demographic attributes like age, education, and income — but also opinions and preferences related to the Star Wars universe, along with geographic and pop culture context. This dataset provides a unique lens into how demographic traits (age, education, income) and personal interests (Star Wars fandom, film ranking, Star Trek crossover) intersect. Even within this small sample:\nEducation and age align somewhat with income, but not always predictably.\nStar Wars fans in this sample are more likely to be high earners.\nGeographic and cultural variables are captured and ready to be tested in your machine learning model to see what really drives income predictions.\n\n\n```{python}\n# Filter out people who haven't seen any films\ndf_seen = df[df[\"seen_any\"].notna()].copy()\n\n```\n\n```{python}\n# Convert age to numeric midpoint\nage_map = {\n    \"18-29\": 23.5,\n    \"30-44\": 37,\n    \"45-60\": 52,\n    \"> 60\": 65\n}\ndf_seen[\"age_num\"] = df_seen[\"age\"].map(age_map)\ndf_seen.drop(columns=\"age\", inplace=True)\n\n\n```\n\n```{python}\n# Convert education to numeric\nedu_map = {\n    \"Less than high school degree\": 1,\n    \"High school degree\": 2,\n    \"Some college or Associate degree\": 3,\n    \"Bachelor degree\": 4,\n    \"Graduate degree\": 5\n}\ndf_seen[\"education_num\"] = df_seen[\"education\"].map(edu_map)\ndf_seen.drop(columns=\"education\", inplace=True)\n\n\n```\n\n```{python}\n# Convert income to numeric midpoint\nincome_map = {\n    \"Under $25,000\": 12500,\n    \"$25,000 - $49,999\": 37500,\n    \"$50,000 - $99,999\": 75000,\n    \"$100,000 - $149,999\": 125000,\n    \"$150,000+\": 175000\n}\ndf_seen[\"income_num\"] = df_seen[\"income\"].map(income_map)\ndf_seen.drop(columns=\"income\", inplace=True)\n\n```\n\n```{python}\n# Create binary target variable\ndf_seen[\"target\"] = (df_seen[\"income_num\"] > 50000).astype(int)\n\n```\n\n```{python}\n# Drop rows with NA in essential columns\ndf_seen.dropna(subset=[\"age_num\", \"education_num\", \"income_num\", \"target\"], inplace=True)\n\n# One-hot encode remaining categoricals\ncategorical_cols = df_seen.select_dtypes(include=\"object\").columns\ndf_final = pd.get_dummies(df_seen, columns=categorical_cols, drop_first=True)\ndf_final.head()\n\n\n```\nThis table illustrates how survey responses were converted to numeric formats:\n\nAge, education, and income are now usable numerical columns.\n\nThe target column defines the prediction goal.\n\nEach one-hot encoded column reflects a categorical feature (e.g., gender, location, preferences) as True/False binary flags.\n\nThese transformations ensured that the dataset could be successfully fed into a machine learning pipeline without error, and allowed us to evaluate demographic and preference-based predictors of income with interpretable results.\n\n\n## QUESTION|TASK 3\n\n__Validate that the data provided on GitHub lines up with the article by recreating 2 of the visuals from the article.__  \n\nTo validate the dataset against the original article, I recreated two visualizations: one showing general Star Wars viewership and another showing the most disliked characters. The first chart confirms that the vast majority of respondents have seen at least one of the six Star Wars films, while a much smaller group indicated they had not. This supports the reliability of the rest of the survey, since most participants were familiar with the franchise and could provide informed opinions. The second chart attempts to visualize which characters were viewed most unfavorably. While the underlying logic worked, the chart labels defaulted to generic terms like “Him/Her” due to long or uncleaned column names in the dataset. Nonetheless, the plot shows that respondents had strong negative reactions to at least one character—consistent with the article’s emphasis on Jar Jar Binks being widely disliked. Together, these visualizations affirm that the dataset aligns reasonably well with the original article and contains meaningful patterns in viewership and character sentiment.\n\n\n\n```{python}\n# Try to detect viewership columns\nseen_cols = [col for col in df.columns if \"seen\" in col and \"episode\" in col]\n\nif seen_cols:\n    movie_counts = df[seen_cols].apply(lambda col: col == \"Yes\").sum().sort_values()\n    movie_counts.plot(kind=\"barh\", title=\"Star Wars Movie Viewership\", xlabel=\"Respondents\")\n    plt.tight_layout()\n    plt.show()\nelse:\n    summary_col = \"have_you_seen_any_of_the_6_films_in_the_star_wars_franchise\"\n    if summary_col in df.columns:\n        df[summary_col].value_counts().plot(\n            kind=\"bar\", title=\"Seen Any Star Wars Film?\", ylabel=\"Respondents\"\n        )\n        plt.tight_layout()\n        plt.show()\n    else:\n        print(\"Movie viewership columns not found.\")\n\n```\n\n```{python}\n# Most disliked characters\nchar_cols = [col for col in df.columns if \"unfavorably\" in col or \"character\" in col]\n\nif char_cols:\n    char_votes = df[char_cols].apply(lambda col: col.value_counts().get(\"Very unfavorably\", 0))\n    clean_labels = [\n        col.split(\"with_\")[-1].replace(\"_\", \" \").replace(\".\", \"\").title()\n        for col in char_votes.index\n    ]\n    char_votes.index = clean_labels\n    char_votes.sort_values().plot(\n        kind=\"barh\", figsize=(8, 6), title=\"Most Disliked Star Wars Characters\", color=\"steelblue\"\n    )\n    plt.xlabel(\"Number of 'Very Unfavorably' Votes\")\n    plt.ylabel(\"Character\")\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"Disliked character columns not found.\")\n\n\n```\n\n## QUESTION|TASK 4\n\n__Build a machine learning model that predicts whether a person makes more than $50k. Describe your model and report the accuracy.__ \n\nTo predict whether a respondent earns more than $50,000 annually, I trained a Random Forest Classifier using the cleaned and preprocessed Star Wars survey dataset. The features included age, education level, income, and one-hot encoded responses to various Star Wars-related survey questions. The model achieved an accuracy of 75.71%, significantly outperforming the initial 62% estimate mentioned in the planning stage. The classification report shows a strong ability to correctly identify high-income earners (target = 1), with a precision of 0.76, recall of 0.98, and f1-score of 0.86. While the model struggles more with predicting low-income respondents (target = 0), the overall performance indicates that demographic and cultural preferences in the dataset contain meaningful patterns associated with income.\n```{python}\nX = df_final.drop(columns=[\"income_num\", \"target\"])\ny = df_final[\"target\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Random Forest accuracy: {accuracy:.2%}\")\nprint(classification_report(y_test, y_pred))\n\n```\n\n---\n\n## STRETCH QUESTION|TASK 1\n\n__Build a machine learning model that predicts whether a person makes more than $50k. With accuracy of at least 65%. Describe your model and report the accuracy.__\n\nIn Stretch Task 1, I sought to improve the model beyond 65% accuracy. By tuning hyperparameters (increasing estimators and adjusting depth), we achieved the same 75.71% accuracy on the test set, which meets and exceeds the 65% stretch goal. These results suggest that even in a culturally niche dataset like this, machine learning can effectively model real-world socioeconomic traits when survey data is properly cleaned and engineered.\n\n```{python}\nmodel2 = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\nmodel2.fit(X_train, y_train)\npreds2 = model2.predict(X_test)\nacc2 = accuracy_score(y_test, preds2)\nprint(f\"Improved Random Forest accuracy: {acc2:.2%}\")\n\n\n```\n\n\n## STRETCH QUESTION|TASK 2\n\n__Validate the data provided on GitHub lines up with the article by recreating a 3rd visual from the article.__\n\nTo validate the dataset against the original article, I recreated a third visual showing the distribution of respondents by gender. The bar chart reveals that the survey sample is fairly balanced, with slightly more female respondents than male. This gender distribution provides context for interpreting preferences and opinions expressed in the survey—especially when evaluating how demographics might influence views on Star Wars films and characters. Ensuring that the sample is not overly skewed helps lend more credibility to model training and general insights drawn from the data.\n\n```{python}\nif \"gender\" in df.columns:\n    df[\"gender\"].value_counts().plot(kind=\"bar\", title=\"Respondents by Gender\", ylabel=\"Count\")\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"Gender column not found.\")\n\n```\n\n\n## STRETCH QUESTION|TASK 3\n\n__Create a new column that converts the location groupings to a single number. Drop the location categorical column.__  \n\nTo prepare the dataset for machine learning, I converted the categorical location_(census_region) variable into a numerical format by assigning each region a unique code using pandas' category method. This transformation allows the model to interpret geographic data in a structured, numeric form without introducing artificial ordinal relationships. The original text column was dropped after conversion to avoid redundancy. This step ensures location can now be used as a predictive feature in the model while maintaining a clean and efficient dataset structure.\n\n```{python}\nif \"location_(census_region)\" in df_seen.columns:\n    df_seen[\"location_num\"] = df_seen[\"location_(census_region)\"].astype(\"category\").cat.codes\n    df_seen.drop(columns=\"location_(census_region)\", inplace=True)\n    print(df_seen[[\"location_num\"]].head())\nelse:\n    print(\"Location column not found.\")\n\n\n```\n\n---\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":{"source":false,"toggle":true,"caption":"See code"},"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","include-in-header":[{"text":"<link href=\"https://fonts.googleapis.com/css2?family=Dancing+Script&display=swap\" rel=\"stylesheet\">\n"}],"css":["../styles.css"],"toc":true,"toc-depth":3,"self-contained":true,"number-sections":false,"html-math-method":"katex","output-file":"project5.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","theme":{"light":["flatly","theme.scss"],"dark":["darkly","theme-dark.scss"]},"code-copy":"hover","respect-user-color-scheme":true,"toc-title":"Table of Contents","toc-show":true,"toc-float":true,"toc-float-offset":100,"toc-float-width":300,"toc-float-position":"right","toc-float-breakpoint":768,"toc-float-scroll":true,"toc-float-scroll-offset":50,"toc-float-scroll-duration":300,"toc-float-scroll-easing":"ease-in-out","toc-float-scroll-target":"#toc","title":"Client Report - The War with Star Wars","subtitle":"Course DS 250","author":"Maia Faith Chambers","page-layout":"full","title-block-banner":true,"toc-location":"body","code-summary":"Show the code"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}